{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from Models import Transformer, Encoder, Decoder\n",
    "\n",
    "class myModel(nn.Module):\n",
    "    def __init__(self, vocab_size, src, d_model, N, heads, dropout, n_classes):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(vocab_size, d_model, N, heads, dropout)\n",
    "        self.linear1 = nn.Linear(d_model, 1)\n",
    "        self.linear2 = nn.Linear(src, n_classes)\n",
    "        self.fc = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x, None)\n",
    "        x = self.linear1(x)\n",
    "        x = x.squeeze(-1)\n",
    "        x = self.linear2(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "\n",
    "class KddData(object):\n",
    "\n",
    "    def __init__(self, batch_size, file_name, augmented=False, test_filename=None):\n",
    "        self._encoder = {\n",
    "            'label':    LabelEncoder()\n",
    "        }\n",
    "        self.batch_size = batch_size\n",
    "        if (augmented == False):\n",
    "            pass\n",
    "        else:\n",
    "            data = pd.read_csv(file_name)\n",
    "            target = np.array(data['label'])\n",
    "            features = np.array(data.drop('label', axis=1))\n",
    "            X_train, y_train = self.__encode_data(features, target)\n",
    "            self.train_dataset = TensorDataset(\n",
    "                torch.from_numpy(X_train.astype(np.float32)),\n",
    "                torch.from_numpy(y_train.astype(np.int))\n",
    "            )\n",
    "            test_data = pd.read_csv(test_filename)\n",
    "            target = np.array(test_data['label'])\n",
    "            print(target.shape)\n",
    "            features = np.array(test_data.drop('label', axis=1))\n",
    "            X_test, y_test = self.__encode_data(features, target)\n",
    "            self.test_dataset = TensorDataset(\n",
    "                torch.from_numpy(X_test.astype(np.float32)),\n",
    "                torch.from_numpy(y_test.astype(np.float32))\n",
    "            )\n",
    "            self.train_dataloader = DataLoader(self.train_dataset, self.batch_size, shuffle=True)\n",
    "            self.test_dataloader = DataLoader(self.test_dataset, self.batch_size, shuffle=True)\n",
    "            return\n",
    "        data = pd.read_csv(file_name)\n",
    "        target = np.array(data['label'])\n",
    "        features = np.array(data.drop('label', axis=1))\n",
    "\n",
    "        data_X, data_y = self.__encode_data(features, target)\n",
    "        self.train_dataset, self.test_dataset = self.__split_data_to_tensor(data_X, data_y)\n",
    "        self.train_dataloader = DataLoader(self.train_dataset, self.batch_size, shuffle=True)\n",
    "        self.test_dataloader = DataLoader(self.test_dataset, self.batch_size, shuffle=True)\n",
    "\n",
    "    \"\"\"将数据中字符串部分转换为数字，并将输入的41维特征转换为8*8的矩阵\"\"\"\n",
    "    def __encode_data(self, data_X, data_y):\n",
    "        self._encoder['label'].fit(list(set(data_y)))\n",
    "        data_X = np.pad(data_X, ((0, 0), (0, 100 - len(data_X[0]))), 'constant').reshape(-1, 1, 10, 10)\n",
    "        data_y = self._encoder['label'].transform(data_y)\n",
    "        return data_X, data_y\n",
    "\n",
    "    \"\"\"将数据拆分为训练集和测试集，并转换为TensorDataset对象\"\"\"\n",
    "    def __split_data_to_tensor(self, data_X, data_y):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data_X, data_y, test_size=0.3)\n",
    "        train_dataset = TensorDataset(\n",
    "            torch.from_numpy(X_train.astype(np.float32)),\n",
    "            torch.from_numpy(y_train.astype(np.int))\n",
    "        )\n",
    "        test_dataset = TensorDataset(\n",
    "            torch.from_numpy(X_test.astype(np.float32)),\n",
    "            torch.from_numpy(y_test.astype(np.int))\n",
    "        )\n",
    "        return train_dataset, test_dataset\n",
    "\n",
    "    \"\"\"接受一个数组进行解码\"\"\"\n",
    "    def decode(self, data, label=False):\n",
    "        if not label:\n",
    "            _data = list(data)\n",
    "            _data[1] = self._encoder['protocal'].inverse_transform([_data[1]])[0]\n",
    "            _data[2] = self._encoder['service'].inverse_transform([_data[2]])[0]\n",
    "            _data[2] = self._encoder['flag'].inverse_transform([_data[3]])[0]\n",
    "            return _data\n",
    "        return self._encoder['label'].inverse_transform(data)\n",
    "    \n",
    "    def encode(self, data, label=False):\n",
    "        if not label:\n",
    "            _data = list(data)\n",
    "            _data[1] = self._encoder['protocal'].transform([_data[1]])[0]\n",
    "            _data[2] = self._encoder['service'].transform([_data[2]])[0]\n",
    "            _data[3] = self._encoder['flag'].transform([_data[3]])[0]\n",
    "            return _data\n",
    "        return self._encoder['label'].transform([data])[0]\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "# dataset.train_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400,)\n",
      "epoch 1\n",
      "**********\n",
      "Finish 1 epoch, Loss: 0.637572, Acc: 0.640312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-b968ec25cb74>:64: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  img = Variable(img, volatile=True).cuda()\n",
      "<ipython-input-3-b968ec25cb74>:65: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  label = Variable(label, volatile=True).cuda()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.471866, Acc: 0.746667\n",
      "\n",
      "epoch 2\n",
      "**********\n",
      "Finish 2 epoch, Loss: 0.472201, Acc: 0.784375\n",
      "Test Loss: 0.532957, Acc: 0.675417\n",
      "\n",
      "epoch 3\n",
      "**********\n",
      "Finish 3 epoch, Loss: 0.341046, Acc: 0.862083\n",
      "Test Loss: 0.440816, Acc: 0.827917\n",
      "\n",
      "epoch 4\n",
      "**********\n",
      "Finish 4 epoch, Loss: 0.267104, Acc: 0.891563\n",
      "Test Loss: 0.280507, Acc: 0.872917\n",
      "\n",
      "epoch 5\n",
      "**********\n",
      "Finish 5 epoch, Loss: 0.203584, Acc: 0.921146\n",
      "Test Loss: 0.147266, Acc: 0.952500\n",
      "\n",
      "epoch 6\n",
      "**********\n",
      "Finish 6 epoch, Loss: 0.183398, Acc: 0.931562\n",
      "Test Loss: 0.135873, Acc: 0.956667\n",
      "\n",
      "epoch 7\n",
      "**********\n",
      "Finish 7 epoch, Loss: 0.153665, Acc: 0.945312\n",
      "Test Loss: 0.117709, Acc: 0.961250\n",
      "\n",
      "epoch 8\n",
      "**********\n",
      "Finish 8 epoch, Loss: 0.131907, Acc: 0.953958\n",
      "Test Loss: 0.260290, Acc: 0.890833\n",
      "\n",
      "epoch 9\n",
      "**********\n",
      "Finish 9 epoch, Loss: 0.128110, Acc: 0.958125\n",
      "Test Loss: 0.100950, Acc: 0.968750\n",
      "\n",
      "epoch 10\n",
      "**********\n",
      "Finish 10 epoch, Loss: 0.108868, Acc: 0.963229\n",
      "Test Loss: 0.093776, Acc: 0.968750\n",
      "\n",
      "epoch 11\n",
      "**********\n",
      "Finish 11 epoch, Loss: 0.109519, Acc: 0.963333\n",
      "Test Loss: 0.117483, Acc: 0.960833\n",
      "\n",
      "epoch 12\n",
      "**********\n",
      "Finish 12 epoch, Loss: 0.100585, Acc: 0.968125\n",
      "Test Loss: 0.087705, Acc: 0.969167\n",
      "\n",
      "epoch 13\n",
      "**********\n",
      "Finish 13 epoch, Loss: 0.089506, Acc: 0.972708\n",
      "Test Loss: 0.080439, Acc: 0.973750\n",
      "\n",
      "epoch 14\n",
      "**********\n",
      "Finish 14 epoch, Loss: 0.090572, Acc: 0.971042\n",
      "Test Loss: 0.085791, Acc: 0.973333\n",
      "\n",
      "epoch 15\n",
      "**********\n",
      "Finish 15 epoch, Loss: 0.085293, Acc: 0.974583\n",
      "Test Loss: 0.073998, Acc: 0.975417\n",
      "\n",
      "epoch 16\n",
      "**********\n",
      "Finish 16 epoch, Loss: 0.081019, Acc: 0.974792\n",
      "Test Loss: 0.072486, Acc: 0.975000\n",
      "\n",
      "epoch 17\n",
      "**********\n",
      "Finish 17 epoch, Loss: 0.077749, Acc: 0.978021\n",
      "Test Loss: 0.071278, Acc: 0.976250\n",
      "\n",
      "epoch 18\n",
      "**********\n",
      "Finish 18 epoch, Loss: 0.090253, Acc: 0.971042\n",
      "Test Loss: 0.069267, Acc: 0.976667\n",
      "\n",
      "epoch 19\n",
      "**********\n",
      "Finish 19 epoch, Loss: 0.070553, Acc: 0.978437\n",
      "Test Loss: 0.068318, Acc: 0.977083\n",
      "\n",
      "epoch 20\n",
      "**********\n",
      "Finish 20 epoch, Loss: 0.071808, Acc: 0.977917\n",
      "Test Loss: 0.077056, Acc: 0.977500\n",
      "\n",
      "epoch 21\n",
      "**********\n",
      "Finish 21 epoch, Loss: 0.071716, Acc: 0.977604\n",
      "Test Loss: 0.062928, Acc: 0.977917\n",
      "\n",
      "epoch 22\n",
      "**********\n",
      "Finish 22 epoch, Loss: 0.068660, Acc: 0.980000\n",
      "Test Loss: 0.061132, Acc: 0.978750\n",
      "\n",
      "epoch 23\n",
      "**********\n",
      "Finish 23 epoch, Loss: 0.068415, Acc: 0.979271\n",
      "Test Loss: 0.059788, Acc: 0.980417\n",
      "\n",
      "epoch 24\n",
      "**********\n",
      "Finish 24 epoch, Loss: 0.064851, Acc: 0.980313\n",
      "Test Loss: 0.060331, Acc: 0.981250\n",
      "\n",
      "epoch 25\n",
      "**********\n",
      "Finish 25 epoch, Loss: 0.063113, Acc: 0.981458\n",
      "Test Loss: 0.068673, Acc: 0.977917\n",
      "\n",
      "epoch 26\n",
      "**********\n",
      "Finish 26 epoch, Loss: 0.065839, Acc: 0.979792\n",
      "Test Loss: 0.060040, Acc: 0.979167\n",
      "\n",
      "epoch 27\n",
      "**********\n",
      "Finish 27 epoch, Loss: 0.060860, Acc: 0.982083\n",
      "Test Loss: 0.057784, Acc: 0.982500\n",
      "\n",
      "epoch 28\n",
      "**********\n",
      "Finish 28 epoch, Loss: 0.059310, Acc: 0.981667\n",
      "Test Loss: 0.057655, Acc: 0.980833\n",
      "\n",
      "epoch 29\n",
      "**********\n",
      "Finish 29 epoch, Loss: 0.057419, Acc: 0.981563\n",
      "Test Loss: 0.062411, Acc: 0.978333\n",
      "\n",
      "epoch 30\n",
      "**********\n",
      "Finish 30 epoch, Loss: 0.055756, Acc: 0.982812\n",
      "Test Loss: 0.059982, Acc: 0.980417\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "# 神经网络参数\n",
    "batch_size = 128\n",
    "learning_rate = 5e-3\n",
    "num_epoches = 30\n",
    "USE_GPU = torch.cuda.is_available()\n",
    "\n",
    "data_file = \"E:\\THU\\科研\\SRT\\cross_network_defense\\model_reproduce\\dataset\\\\train-expon-nagle-open.csv\"\n",
    "test_file = \"E:\\THU\\科研\\SRT\\cross_network_defense\\model_reproduce\\dataset\\\\test-lossRate-0.csv\"\n",
    "dataset = KddData(batch_size, file_name=data_file, augmented=True, test_filename=test_file)\n",
    "model = myModel(1500, 100, 8, 6, 8, 0.1, 1)\n",
    "model = model.cuda()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epoches):\n",
    "    print('epoch {}'.format(epoch + 1))\n",
    "    print('*' * 10)\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    for i, data in enumerate(dataset.train_dataloader, 1):\n",
    "        model.train()\n",
    "        x, label = data\n",
    "        # Reshape x and convert to LongTensor\n",
    "        x = x.reshape(x.size(0),  100)\n",
    "        x = Variable(x)\n",
    "        x = x.long()\n",
    "        #print(x.max())\n",
    "        #print(x.min())\n",
    "        x = x.cuda()\n",
    "        label = label.reshape(label.size(0), 1)\n",
    "        label = label.float()\n",
    "        label = label.cuda()\n",
    "        out = model(x)\n",
    "        #print(out)\n",
    "        #print(label)\n",
    "        loss = criterion(out, label)\n",
    "        running_loss += loss.item() * label.size(0)\n",
    "        pred = torch.round(out)\n",
    "        num_correct = (pred == label).sum()\n",
    "        #print(\"num_correct = \" + str(num_correct))\n",
    "        accuracy = (pred == label).float().mean()\n",
    "        running_acc += num_correct.item()\n",
    "            \n",
    "        # Back Propagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print('Finish {} epoch, Loss: {:.6f}, Acc: {:.6f}'.format(\n",
    "            epoch + 1, running_loss / (len(dataset.train_dataset)), running_acc / (len(\n",
    "                dataset.train_dataset))))\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    eval_acc = 0\n",
    "    for data in dataset.test_dataloader:\n",
    "        img, label = data\n",
    "        img = img.reshape(img.size(0), 100).long()\n",
    "        label = label.reshape(label.size(0), 1)\n",
    "        if USE_GPU:\n",
    "            img = Variable(img, volatile=True).cuda()\n",
    "            label = Variable(label, volatile=True).cuda()\n",
    "        else:\n",
    "            img = Variable(img, volatile=True)\n",
    "            label = Variable(label, volatile=True)\n",
    "        out = model(img)\n",
    "        loss = criterion(out, label.float())\n",
    "        eval_loss += loss.item() * label.size(0)\n",
    "        pred = torch.round(out)\n",
    "        num_correct = (pred == label).sum()\n",
    "        eval_acc += num_correct.item()\n",
    "    print('Test Loss: {:.6f}, Acc: {:.6f}'.format(eval_loss / (len(\n",
    "            dataset.test_dataset)), eval_acc / (len(dataset.test_dataset))))\n",
    "    print()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "37b255bb5dc0d995b91bd1b934b878e610a26475f52eafaf29fdb395fb105534"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
